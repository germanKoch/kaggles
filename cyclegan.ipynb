{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndef show_img(tensors):\n    plt.figure(figsize=(15, 15))\n        \n    fig, ax = plt.subplots(len(tensors)//3 + 1, 3)\n    for index, tensor in enumerate(tensors):\n        ax[index].imshow(tensor.squeeze().permute(1,2,0).detach().numpy())\n    plt.show()\n            ","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:33:40.415093Z","iopub.execute_input":"2024-06-09T19:33:40.416022Z","iopub.status.idle":"2024-06-09T19:33:40.422037Z","shell.execute_reply.started":"2024-06-09T19:33:40.415986Z","shell.execute_reply":"2024-06-09T19:33:40.421095Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"# load adatasets\nimport os\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom torch.optim import lr_scheduler\nimport itertools\nimport random\n\nclass ImageFolderDataset(Dataset):\n    def __init__(self, first_dir, second_dir, transform=None):\n        self.first_dir = first_dir\n        self.second_dir = second_dir\n        \n        self.transform = transform\n        self.first_dir_paths = [os.path.join(first_dir, fname) for fname in os.listdir(first_dir) if fname.endswith(('png', 'jpg', 'jpeg'))]\n        self.second_dir_paths = [os.path.join(second_dir, fname) for fname in os.listdir(second_dir) if fname.endswith(('png', 'jpg', 'jpeg'))]\n        self.cache_first = dict()\n        self.cache_second = dict()\n\n    def __len__(self):\n        return min(len(self.first_dir_paths), len(self.second_dir_paths))\n\n    def __getitem__(self, idx):        \n        first_img_path = self.first_dir_paths[idx]\n        second_img_path = self.second_dir_paths[idx]\n        \n        if first_img_path in self.cache_first:\n            first_image = self.cache_first[first_img_path]\n        else:\n            first_image = Image.open(first_img_path).convert(\"RGB\")\n            self.cache_first[first_img_path] = first_image\n            \n        if second_img_path in self.cache_second:\n            second_image = self.cache_second[second_img_path]\n        else:\n            second_image = Image.open(second_img_path).convert(\"RGB\")\n            self.cache_second[second_img_path] = second_image\n        \n        if self.transform:\n            first_image = self.transform(first_image)\n            second_image = self.transform(second_image)\n        return first_image, second_image\n    \nclass ImageBuffer():\n    def __init__(self):\n        self.buffer = []\n        self.max_size = 50\n    \n    def push_and_pop(self, datas):\n        return_imgs = []\n        for element in datas.data:\n            element = torch.unsqueeze(element, 0)\n            if len(self.buffer) < self.max_size:\n                self.buffer.append(element)\n                return_imgs.append(element)\n            else:\n                if random.uniform(0, 1) > 0.5:\n                    i = random.randint(0, self.max_size - 1)\n                    return_imgs.append(self.buffer[i].clone())\n                    self.buffer[i] = element\n                else:\n                    return_imgs.append(element)\n                    \n        return torch.cat(return_imgs, 0)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:39:40.758359Z","iopub.execute_input":"2024-06-09T19:39:40.759268Z","iopub.status.idle":"2024-06-09T19:39:40.776176Z","shell.execute_reply.started":"2024-06-09T19:39:40.759214Z","shell.execute_reply":"2024-06-09T19:39:40.775148Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"dataset = ImageFolderDataset('/kaggle/input/gan-getting-started/photo_jpg', '/kaggle/input/gan-getting-started/monet_jpg', transforms.Compose([\n        transforms.Resize((256, 256)),  # Resize the image to 256x256\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n]))\n\ndataloader = DataLoader(dataset=dataset, batch_size=1, shuffle=True, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:39:42.199050Z","iopub.execute_input":"2024-06-09T19:39:42.200055Z","iopub.status.idle":"2024-06-09T19:39:42.227501Z","shell.execute_reply.started":"2024-06-09T19:39:42.200010Z","shell.execute_reply":"2024-06-09T19:39:42.226653Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class conv_block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.conv_1 = nn.Conv2d(\n            in_channels = in_c,\n            out_channels = out_c,\n            kernel_size = 3,\n            padding=1\n        )\n        self.relu_1 = nn.ReLU()\n        self.conv_2 = nn.Conv2d(\n            in_channels = out_c,\n            out_channels = out_c,\n            kernel_size = 3,\n            padding=1\n        )\n        self.relu_2 = nn.ReLU()\n        self.conv_3 = nn.Conv2d(\n            in_channels = out_c,\n            out_channels = out_c,\n            kernel_size = 3,\n            padding=1\n        )\n        self.relu_3 = nn.ReLU()\n        \n    def forward(self, x):\n        x = self.conv_1(x)\n        x = self.relu_1(x)\n        x = self.conv_2(x)\n        x = self.relu_2(x)\n        x = self.conv_3(x)\n        x = self.relu_3(x)\n        return x\n    \nclass EncoderBlock(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.conv = conv_block(in_c, out_c)\n        self.pool = nn.MaxPool2d((2,2))\n    \n    def forward(self, x):\n        x = self.conv(x)\n        p = self.pool(x)\n        return x, p\n    \nclass DecoderBlock(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n        self.conv = conv_block(out_c*2, out_c)\n        \n    def forward(self, x, residual):\n        x = self.up(x)        \n        x = torch.cat([x, residual], axis=1)\n        x = self.conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:39:42.813458Z","iopub.execute_input":"2024-06-09T19:39:42.813833Z","iopub.status.idle":"2024-06-09T19:39:42.829020Z","shell.execute_reply.started":"2024-06-09T19:39:42.813804Z","shell.execute_reply":"2024-06-09T19:39:42.827987Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"class UNET_Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.enc_1 = EncoderBlock(3, 64) # (64, 128, 128)\n        self.enc_2 = EncoderBlock(64, 128) # (128, 64, 64)\n        self.enc_3 = EncoderBlock(128, 256) # (256, 32, 32)\n        self.enc_4 = EncoderBlock(256, 512) # (512, 16, 16)\n        \n        self.bridge = conv_block(512, 1024) # (1024, 16, 16)\n        \n        self.dec_1 = DecoderBlock(1024, 512) # (512, 32, 32)\n        self.dec_2 = DecoderBlock(512, 256) # (256, 64, 64)\n        self.dec_3 = DecoderBlock(256, 128) # (128, 128, 128)\n        self.dec_4 = DecoderBlock(128, 64) # (64, 256, 256)\n        \n        self.final = nn.Conv2d(64, 3, kernel_size=1, padding=0)\n        self.activation = nn.Tanh()\n        \n    def forward(self, x):\n        x_enc_1, x = self.enc_1(x)        \n        x_enc_2, x = self.enc_2(x)        \n        x_enc_3, x = self.enc_3(x)        \n        x_enc_4, x = self.enc_4(x)\n        \n        bridge = self.bridge(x)\n        \n        result = self.dec_1(bridge, x_enc_4)  \n        result = self.dec_2(result, x_enc_3)\n        result = self.dec_3(result, x_enc_2)\n        result = self.dec_4(result, x_enc_1)\n        \n        result = self.final(result)\n        result = self.activation(result)\n        return result\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:39:43.231809Z","iopub.execute_input":"2024-06-09T19:39:43.232187Z","iopub.status.idle":"2024-06-09T19:39:43.242424Z","shell.execute_reply.started":"2024-06-09T19:39:43.232156Z","shell.execute_reply":"2024-06-09T19:39:43.241443Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"class DownSampleDis(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, isNorm=True):\n        super().__init__()\n        self._isNorm = isNorm\n        \n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2)\n        self.norm = nn.InstanceNorm2d(out_channels)\n        self.relu = nn.LeakyReLU(negative_slope=0.2)\n        \n    def forward(self, x):\n        out = self.conv(x)\n        if self._isNorm:\n            out = self.norm(out)\n        out = self.relu(out)\n        return out\n    \nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.network = []\n        self.network.append(DownSampleDis(in_channels=3, out_channels=64, kernel_size=4, stride=2, isNorm=False))\n        self.network.append(DownSampleDis(in_channels=64, out_channels=128, kernel_size=4, stride=2))\n        self.network.append(DownSampleDis(in_channels=128, out_channels=256, kernel_size=4, stride=2))\n        self.network.append(DownSampleDis(in_channels=256, out_channels=512, kernel_size=4, stride=2))\n        self.network.append(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1))\n        self.avg_pool = nn.AvgPool2d((14,14))\n        self.model = nn.Sequential(*self.network)\n\n    def forward(self, x):\n        x = self.model(x)\n        x = nn.Dropout(0.5)(x)\n        return self.avg_pool(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:39:43.483875Z","iopub.execute_input":"2024-06-09T19:39:43.484263Z","iopub.status.idle":"2024-06-09T19:39:43.497278Z","shell.execute_reply.started":"2024-06-09T19:39:43.484233Z","shell.execute_reply":"2024-06-09T19:39:43.495946Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nL_CYCLE = 10\nL_ID = 5\nEPOCHS = 20\nDECAY_EPOCHS = 20\nLR = 2e-4\n# Model\nUSE_IDENTITY = True","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:39:44.180422Z","iopub.execute_input":"2024-06-09T19:39:44.181304Z","iopub.status.idle":"2024-06-09T19:39:44.186154Z","shell.execute_reply.started":"2024-06-09T19:39:44.181268Z","shell.execute_reply":"2024-06-09T19:39:44.185144Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"a_b_generator = UNET_Generator().to(DEVICE)\nb_a_generator = UNET_Generator().to(DEVICE)\n\na_discriminator = Discriminator().to(DEVICE)\nb_discriminator = Discriminator().to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:39:44.475323Z","iopub.execute_input":"2024-06-09T19:39:44.475640Z","iopub.status.idle":"2024-06-09T19:39:45.523368Z","shell.execute_reply.started":"2024-06-09T19:39:44.475615Z","shell.execute_reply":"2024-06-09T19:39:45.522546Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# loss function\ncriterion_GAN = nn.MSELoss()\ncriterion_cycle = nn.L1Loss()\ncriterion_identity = nn.L1Loss()\n\n# Optimizer & LR scheduler\noptimizer_g = torch.optim.Adam(itertools.chain(a_b_generator.parameters(), b_a_generator.parameters()), lr=LR, betas=(0.5, 0.999))\noptimizer_d = torch.optim.Adam(itertools.chain(a_discriminator.parameters(), b_discriminator.parameters()), lr=LR, betas=(0.5, 0.999))\n\nLambdaLR = lambda epoch: 1 - max(0, epoch - DECAY_EPOCHS + 1) / (EPOCHS - DECAY_EPOCHS + 1)\nscheduler_G = lr_scheduler.LambdaLR(optimizer_g, lr_lambda=LambdaLR)\nscheduler_D = lr_scheduler.LambdaLR(optimizer_d, lr_lambda=LambdaLR)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:39:45.524980Z","iopub.execute_input":"2024-06-09T19:39:45.525278Z","iopub.status.idle":"2024-06-09T19:39:45.536175Z","shell.execute_reply.started":"2024-06-09T19:39:45.525252Z","shell.execute_reply":"2024-06-09T19:39:45.535259Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nfrom tqdm.auto import tqdm\nlogger = list()\n\nfor epoch in range(1, EPOCHS+1):\n    loss_batch = defaultdict(float)\n    x_fake_a_buffer = ImageBuffer()\n    x_fake_b_buffer = ImageBuffer()\n    \n    total_g_loss = 0.0\n    total_d_loss = 0.0\n    \n    for i, data in enumerate(tqdm(dataloader)):\n        # Data\n        x_a = data[0].to(DEVICE) #photo\n        x_b = data[1].to(DEVICE) #monet\n\n        # Generators\n        a_b_generator.zero_grad()\n        b_a_generator.zero_grad()\n\n        # Generate\n        x_fake_a = b_a_generator(x_b)\n        x_fake_b = a_b_generator(x_a)\n\n        # Adversarial\n        x_adv_a = a_discriminator(x_fake_a)\n        x_adv_b = b_discriminator(x_fake_b)\n\n        # Cycle\n        x_cycle_a = b_a_generator(x_fake_b)\n        x_cycle_b = a_b_generator(x_fake_a)\n\n        # Adversarial loss\n        g_loss_adv_a = criterion_GAN(x_adv_a, torch.ones_like(x_adv_a))\n        g_loss_adv_b = criterion_GAN(x_adv_b, torch.ones_like(x_adv_b))\n\n        # Cycle loss\n        g_loss_cycle_a = criterion_cycle(x_cycle_a, x_a) * L_CYCLE \n        g_loss_cycle_b = criterion_cycle(x_cycle_b, x_b) * L_CYCLE\n\n        # Identity loss\n        g_loss_identity_a = criterion_identity(x_cycle_a, x_a) * L_ID if USE_IDENTITY else 0\n        g_loss_identity_b = criterion_identity(x_cycle_b, x_b) * L_ID if USE_IDENTITY else 0\n\n        g_loss_a = g_loss_adv_a + g_loss_cycle_a + g_loss_identity_a\n        g_loss_b = g_loss_adv_a + g_loss_cycle_b + g_loss_identity_b\n        g_loss = (g_loss_a + g_loss_b) / 2 \n              \n        g_loss.backward()\n        total_g_loss += g_loss.item()\n\n        optimizer_g.step()\n\n        # Discriminators\n        a_discriminator.zero_grad()\n        b_discriminator.zero_grad()\n\n        # photo\n        x_fake_a = x_fake_a_buffer.push_and_pop(x_fake_a)\n        d_real_a = a_discriminator(x_a)\n        d_fake_a = a_discriminator(x_fake_a.detach())\n        \n        # monet\n        x_fake_b = x_fake_b_buffer.push_and_pop(x_fake_b)\n        d_real_b = b_discriminator(x_b)\n        d_fake_b = b_discriminator(x_fake_b.detach())\n\n        # Discriminator Loss\n        d_loss_a = criterion_GAN(d_real_a, torch.ones_like(d_real_a)) + criterion_GAN(d_fake_a, torch.zeros_like(d_fake_a))\n        d_loss_b = criterion_GAN(d_real_b, torch.ones_like(d_real_b)) + criterion_GAN(d_fake_b, torch.zeros_like(d_fake_b))\n\n        d_loss = (d_loss_a + d_loss_b) / 2\n\n        d_loss.backward()\n        total_d_loss += d_loss.item()\n        optimizer_d.step()\n    \n    avg_g_loss = total_g_loss / len(dataloader)\n    avg_d_loss = total_d_loss / len(dataloader)\n    \n    logger.append({\n        'g_loss': avg_g_loss,\n        'd_loss': avg_d_loss\n    })\n\n    scheduler_G.step()\n    scheduler_D.step()\n    \n    print(f\"Epoch: {epoch} | Generator Loss: {avg_g_loss} | Discriminator Loss: {avg_d_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:39:45.537674Z","iopub.execute_input":"2024-06-09T19:39:45.538022Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f1f9eccd69f4fbc8a6e7847a3fb82af"}},"metadata":{}},{"name":"stdout","text":"Epoch: 1 | Generator Loss: 3.9004535869757335 | Discriminator Loss: 0.29581872376458096\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc37fedeca04f92aa53615e3268dceb"}},"metadata":{}},{"name":"stdout","text":"Epoch: 2 | Generator Loss: 3.1115933799743654 | Discriminator Loss: 0.24502927450463174\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87c70dbff149438bb6d1c316bfd671ce"}},"metadata":{}},{"name":"stdout","text":"Epoch: 3 | Generator Loss: 2.2483800979455313 | Discriminator Loss: 0.33627397889271377\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2dbcf286eec4feaa1a70f76bd0fb40e"}},"metadata":{}},{"name":"stdout","text":"Epoch: 4 | Generator Loss: 2.0128886226812996 | Discriminator Loss: 0.2733846619042257\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ae19d48156408cb8ee6f564fa92a8d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 5 | Generator Loss: 2.05638860364755 | Discriminator Loss: 0.23467831501116354\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ceb4cc731f14c7ca0fc67090fad9c26"}},"metadata":{}},{"name":"stdout","text":"Epoch: 6 | Generator Loss: 1.9803962528705596 | Discriminator Loss: 0.2619855580323686\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94edb47bdaf54b76867a2ee40abf26ad"}},"metadata":{}},{"name":"stdout","text":"Epoch: 7 | Generator Loss: 1.8110735801855724 | Discriminator Loss: 0.2338515118478487\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c6a33e9e3df486b89c5872a273293e3"}},"metadata":{}},{"name":"stdout","text":"Epoch: 8 | Generator Loss: 1.772278730869293 | Discriminator Loss: 0.2376867609253774\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe929ddd90c0444e9ccefe55ddca1cf8"}},"metadata":{}},{"name":"stdout","text":"Epoch: 9 | Generator Loss: 1.6700958387056986 | Discriminator Loss: 0.23358524161080518\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"034c1c285c9f4bf590ef4a5c8aa219ba"}},"metadata":{}},{"name":"stdout","text":"Epoch: 10 | Generator Loss: 1.5736077708005904 | Discriminator Loss: 0.23070924300079546\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4550192bf51c4791ae47268ee3e3afd2"}},"metadata":{}},{"name":"stdout","text":"Epoch: 11 | Generator Loss: 1.6243758090337117 | Discriminator Loss: 0.22867893428231278\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aaf13af60054f0caaea78adf52f2bfb"}},"metadata":{}},{"name":"stdout","text":"Epoch: 12 | Generator Loss: 1.5405838578939437 | Discriminator Loss: 0.21413319632876665\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9abb2aa71b9a45a9a4b9134c4c88aeef"}},"metadata":{}},{"name":"stdout","text":"Epoch: 13 | Generator Loss: 1.4861938641468684 | Discriminator Loss: 0.21031364852252105\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f949d90a6ba442909f613bfbe2435b8f"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}