{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndef show_img(tensors):\n    plt.figure(figsize=(15, 15))\n        \n    fig, ax = plt.subplots(len(tensors)//3 + 1, 3)\n    for index, tensor in enumerate(tensors):\n        ax[index].imshow(tensor.squeeze().permute(1,2,0).detach().numpy())\n    plt.show()\n            ","metadata":{"execution":{"iopub.status.busy":"2024-06-09T17:42:45.027983Z","iopub.execute_input":"2024-06-09T17:42:45.028424Z","iopub.status.idle":"2024-06-09T17:42:45.065034Z","shell.execute_reply.started":"2024-06-09T17:42:45.028380Z","shell.execute_reply":"2024-06-09T17:42:45.063729Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"# load adatasets\nimport os\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom torch.optim import lr_scheduler\nimport itertools\n\nclass ImageFolderDataset(Dataset):\n    def __init__(self, first_dir, second_dir, transform=None):\n        self.first_dir = first_dir\n        self.second_dir = second_dir\n        \n        self.transform = transform\n        self.first_dir_paths = [os.path.join(first_dir, fname) for fname in os.listdir(first_dir) if fname.endswith(('png', 'jpg', 'jpeg'))]\n        self.second_dir_paths = [os.path.join(second_dir, fname) for fname in os.listdir(second_dir) if fname.endswith(('png', 'jpg', 'jpeg'))]\n        self.cache_first = dict()\n        self.cache_second = dict()\n\n    def __len__(self):\n        return min(len(self.first_dir_paths), len(self.second_dir_paths))\n\n    def __getitem__(self, idx):        \n        first_img_path = self.first_dir_paths[idx]\n        second_img_path = self.second_dir_paths[idx]\n        \n        if first_img_path in self.cache_first:\n            first_image = self.cache_first[first_img_path]\n        else:\n            first_image = Image.open(first_img_path).convert(\"RGB\")\n            self.cache_first[first_img_path] = first_image\n            \n        if second_img_path in self.cache_second:\n            second_image = self.cache_second[second_img_path]\n        else:\n            second_image = Image.open(second_img_path).convert(\"RGB\")\n            self.cache_second[second_img_pazth] = second_image\n        \n        if self.transform:\n            first_image = self.transform(first_image)\n            second_image = self.transform(second_image)\n        return first_image, second_image\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:05:39.001164Z","iopub.execute_input":"2024-06-09T18:05:39.001572Z","iopub.status.idle":"2024-06-09T18:05:39.013187Z","shell.execute_reply.started":"2024-06-09T18:05:39.001541Z","shell.execute_reply":"2024-06-09T18:05:39.011992Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"dataset = ImageFolderDataset('/kaggle/input/gan-getting-started/photo_jpg', '/kaggle/input/gan-getting-started/monet_jpg', transforms.Compose([\n        transforms.Resize((256, 256)),  # Resize the image to 256x256\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n]))\n\ndataloader = DataLoader(dataset=dataset, batch_size=1, shuffle=True, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:23:24.781049Z","iopub.execute_input":"2024-06-09T18:23:24.781430Z","iopub.status.idle":"2024-06-09T18:23:24.813167Z","shell.execute_reply.started":"2024-06-09T18:23:24.781400Z","shell.execute_reply":"2024-06-09T18:23:24.812016Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class conv_block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.conv_1 = nn.Conv2d(\n            in_channels = in_c,\n            out_channels = out_c,\n            kernel_size = 3,\n            padding=1\n        )\n        self.relu_1 = nn.ReLU()\n        self.conv_2 = nn.Conv2d(\n            in_channels = out_c,\n            out_channels = out_c,\n            kernel_size = 3,\n            padding=1\n        )\n        self.relu_2 = nn.ReLU()\n        self.conv_3 = nn.Conv2d(\n            in_channels = out_c,\n            out_channels = out_c,\n            kernel_size = 3,\n            padding=1\n        )\n        self.relu_3 = nn.ReLU()\n        \n    def forward(self, x):\n        x = self.conv_1(x)\n        x = self.relu_1(x)\n        x = self.conv_2(x)\n        x = self.relu_2(x)\n        x = self.conv_3(x)\n        x = self.relu_3(x)\n        return x\n    \nclass EncoderBlock(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.conv = conv_block(in_c, out_c)\n        self.pool = nn.MaxPool2d((2,2))\n    \n    def forward(self, x):\n        x = self.conv(x)\n        p = self.pool(x)\n        return x, p\n    \nclass DecoderBlock(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n        self.conv = conv_block(out_c*2, out_c)\n        \n    def forward(self, x, residual):\n        x = self.up(x)        \n        x = torch.cat([x, residual], axis=1)\n        x = self.conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-09T17:43:03.818407Z","iopub.execute_input":"2024-06-09T17:43:03.818838Z","iopub.status.idle":"2024-06-09T17:43:03.831925Z","shell.execute_reply.started":"2024-06-09T17:43:03.818793Z","shell.execute_reply":"2024-06-09T17:43:03.830605Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class UNET_Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.enc_1 = EncoderBlock(3, 64) # (64, 128, 128)\n        self.enc_2 = EncoderBlock(64, 128) # (128, 64, 64)\n        self.enc_3 = EncoderBlock(128, 256) # (256, 32, 32)\n        self.enc_4 = EncoderBlock(256, 512) # (512, 16, 16)\n        \n        self.bridge = conv_block(512, 1024) # (1024, 16, 16)\n        \n        self.dec_1 = DecoderBlock(1024, 512) # (512, 32, 32)\n        self.dec_2 = DecoderBlock(512, 256) # (256, 64, 64)\n        self.dec_3 = DecoderBlock(256, 128) # (128, 128, 128)\n        self.dec_4 = DecoderBlock(128, 64) # (64, 256, 256)\n        \n        self.final = nn.Conv2d(64, 3, kernel_size=1, padding=0)\n        self.activation = nn.Tanh()\n        \n    def forward(self, x):\n        x_enc_1, x = self.enc_1(x)        \n        x_enc_2, x = self.enc_2(x)        \n        x_enc_3, x = self.enc_3(x)        \n        x_enc_4, x = self.enc_4(x)\n        \n        bridge = self.bridge(x)\n        \n        result = self.dec_1(bridge, x_enc_4)  \n        result = self.dec_2(result, x_enc_3)\n        result = self.dec_3(result, x_enc_2)\n        result = self.dec_4(result, x_enc_1)\n        \n        result = self.final(result)\n        result = self.activation(result)\n        return result\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:03:08.491375Z","iopub.execute_input":"2024-06-09T18:03:08.491778Z","iopub.status.idle":"2024-06-09T18:03:08.501306Z","shell.execute_reply.started":"2024-06-09T18:03:08.491724Z","shell.execute_reply":"2024-06-09T18:03:08.500090Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class DownSampleDis(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, isNorm=True):\n        super().__init__()\n        self._isNorm = isNorm\n        \n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2)\n        self.norm = nn.InstanceNorm2d(out_channels)\n        self.relu = nn.LeakyReLU(negative_slope=0.2)\n        \n    def forward(self, x):\n        out = self.conv(x)\n        if self._isNorm:\n            out = self.norm(out)\n        out = self.relu(out)\n        return out\n    \nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.network = []\n        self.network.append(DownSampleDis(in_channels=3, out_channels=64, kernel_size=4, stride=2, isNorm=False))\n        self.network.append(DownSampleDis(in_channels=64, out_channels=128, kernel_size=4, stride=2))\n        self.network.append(DownSampleDis(in_channels=128, out_channels=256, kernel_size=4, stride=2))\n        self.network.append(DownSampleDis(in_channels=256, out_channels=512, kernel_size=4, stride=2))\n        self.network.append(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1))\n        self.avg_pool = nn.AvgPool2d((14,14))\n        self.model = nn.Sequential(*self.network)\n\n    def forward(self, x):\n        x = self.model(x)\n        x = nn.Dropout(0.5)(x)\n        return self.avg_pool(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:03:08.672705Z","iopub.execute_input":"2024-06-09T18:03:08.673112Z","iopub.status.idle":"2024-06-09T18:03:08.684722Z","shell.execute_reply.started":"2024-06-09T18:03:08.673081Z","shell.execute_reply":"2024-06-09T18:03:08.683610Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nL_CYCLE = 10\nL_ID = 5\nEPOCHS = 20\nDECAY_EPOCHS = 20\nLR = 2e-4\n# Model\nUSE_IDENTITY = True","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:15:42.601143Z","iopub.execute_input":"2024-06-09T19:15:42.601517Z","iopub.status.idle":"2024-06-09T19:15:42.607097Z","shell.execute_reply.started":"2024-06-09T19:15:42.601487Z","shell.execute_reply":"2024-06-09T19:15:42.606119Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"a_b_generator = UNET_Generator().to(DEVICE)\nb_a_generator = UNET_Generator().to(DEVICE)\n\na_discriminator = Discriminator().to(DEVICE)\nb_discriminator = Discriminator().to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:15:43.520153Z","iopub.execute_input":"2024-06-09T19:15:43.520529Z","iopub.status.idle":"2024-06-09T19:15:44.738248Z","shell.execute_reply.started":"2024-06-09T19:15:43.520502Z","shell.execute_reply":"2024-06-09T19:15:44.737138Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# loss function\ncriterion_GAN = nn.MSELoss()\ncriterion_cycle = nn.L1Loss()\ncriterion_identity = nn.L1Loss()\n\n# Optimizer & LR scheduler\noptimizer_g = torch.optim.Adam(itertools.chain(a_b_generator.parameters(), b_a_generator.parameters()), lr=LR, betas=(0.5, 0.999))\noptimizer_d = torch.optim.Adam(itertools.chain(a_discriminator.parameters(), b_discriminator.parameters()), lr=LR, betas=(0.5, 0.999))\n\nLambdaLR = lambda epoch: 1 - max(0, epoch - DECAY_EPOCHS + 1) / (EPOCHS - DECAY_EPOCHS + 1)\nscheduler_G = lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR)\nscheduler_D = lr_scheduler.LambdaLR(optimizer_D, lr_lambda=LambdaLR)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:15:46.001371Z","iopub.execute_input":"2024-06-09T19:15:46.001731Z","iopub.status.idle":"2024-06-09T19:15:46.010765Z","shell.execute_reply.started":"2024-06-09T19:15:46.001705Z","shell.execute_reply":"2024-06-09T19:15:46.009609Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nfrom tqdm.auto import tqdm\nlogger = list()\n\nfor epoch in range(1, EPOCHS+1):\n    loss_batch = defaultdict(float)\n    x_fake_a_buffer = ImageBuffer()\n    x_fake_b_buffer = ImageBuffer()\n    \n    total_g_loss = 0.0\n    total_d_loss = 0.0\n    \n    for i, data in enumerate(tqdm(dataloader)):\n        # Data\n        x_a = data[0].to(DEVICE) #photo\n        x_b = data[1].to(DEVICE) #monet\n\n        # Generators\n        a_b_generator.zero_grad()\n        b_a_generator.zero_grad()\n\n        # Generate\n        x_fake_a = b_a_generator(x_b)\n        x_fake_b = a_b_generator(x_a)\n\n        # Adversarial\n        x_adv_a = a_discriminator(x_fake_a)\n        x_adv_b = b_discriminator(x_fake_b)\n\n        # Cycle\n        x_cycle_a = b_a_generator(x_fake_b)\n        x_cycle_b = a_b_generator(x_fake_a)\n\n        # Adversarial loss\n        g_loss_adv_a = criterion_GAN(x_adv_a, torch.ones_like(x_adv_a))\n        g_loss_adv_b = criterion_GAN(x_adv_b, torch.ones_like(x_adv_b))\n\n        # Cycle loss\n        g_loss_cycle_a = criterion_cycle(x_cycle_a, x_a) * L_CYCLE \n        g_loss_cycle_b = criterion_cycle(x_cycle_b, x_b) * L_CYCLE\n\n        # Identity loss\n        g_loss_identity_a = criterion_identity(x_cycle_a, x_a) * L_ID if USE_IDENTITY else 0\n        g_loss_identity_b = criterion_identity(x_cycle_b, x_b) * L_ID if USE_IDENTITY else 0\n\n        g_loss_a = g_loss_adv_a + g_loss_cycle_a + g_loss_identity_a\n        g_loss_b = g_loss_adv_a + g_loss_cycle_b + g_loss_identity_b\n        g_loss = (g_loss_a + g_loss_b) / 2 \n              \n        g_loss.backward()\n        total_g_loss += g_loss.item()\n\n        optimizer_g.step()\n\n        # Discriminators\n        a_discriminator.zero_grad()\n        b_discriminator.zero_grad()\n\n        # photo\n        x_fake_a = x_fake_a_buffer.push_and_pop(x_fake_a)\n        d_real_a = a_discriminator(x_a)\n        d_fake_a = a_discriminator(x_fake_a.detach())\n        \n        # monet\n        x_fake_b = x_fake_b_buffer.push_and_pop(x_fake_b)\n        d_real_b = b_discriminator(x_b)\n        d_fake_b = b_discriminator(x_fake_b.detach())\n\n        # Discriminator Loss\n        d_loss_a = criterion_GAN(d_real_a, torch.ones_like(d_real_a)) + criterion_GAN(d_fake_a, torch.zeros_like(d_fake_a))\n        d_loss_b = criterion_GAN(d_real_b, torch.ones_like(d_real_b)) + criterion_GAN(d_fake_b, torch.zeros_like(d_fake_b))\n\n        d_loss = (d_loss_a + d_loss_b) / 2\n\n        d_loss.backward()\n        total_d_loss += d_loss.item()\n        optimizer_D.step()\n    \n    avg_g_loss = total_g_loss / len(dataloader)\n    avg_d_loss = total_d_loss / len(dataloader)\n    \n    logger.append({\n        'g_loss': avg_g_loss,\n        'd_loss': avg_d_loss\n    })\n\n    scheduler_G.step()\n    scheduler_D.step()\n    \n    print(f\"Epoch: {epoch} | Generator Loss: {avg_g_loss} | Discriminator Loss: {avg_d_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:15:46.912761Z","iopub.execute_input":"2024-06-09T19:15:46.913408Z","iopub.status.idle":"2024-06-09T19:16:18.983290Z","shell.execute_reply.started":"2024-06-09T19:15:46.913376Z","shell.execute_reply":"2024-06-09T19:16:18.981954Z"},"trusted":true},"execution_count":108,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcfdbfca351440a9bdcdb0fa25b189b1"}},"metadata":{}},{"name":"stdout","text":"torch.Size([1, 1, 14, 14])\ntorch.Size([1, 1, 14, 14])\ntorch.Size([1, 1, 14, 14])\ntorch.Size([1, 1, 14, 14])\ntorch.Size([1, 1, 14, 14])\ntorch.Size([1, 1, 14, 14])\ntorch.Size([1, 1, 14, 14])\ntorch.Size([1, 1, 14, 14])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[108], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m g_loss_b \u001b[38;5;241m=\u001b[39m g_loss_adv_a \u001b[38;5;241m+\u001b[39m g_loss_cycle_b \u001b[38;5;241m+\u001b[39m g_loss_identity_b\n\u001b[1;32m     48\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m (g_loss_a \u001b[38;5;241m+\u001b[39m g_loss_b) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \n\u001b[0;32m---> 50\u001b[0m \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m total_g_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m g_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     53\u001b[0m optimizer_g\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}